Tue 11 Nov 2025 23:30:19 INFO  ['train_bert4rec.py']
Tue 11 Nov 2025 23:30:19 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = False
seed = 2020
state = INFO
reproducibility = True
data_path = /home/nemmer/Documents/Project-A/Second-hand-Web-VietNam/ai-agent/recommender/dataset/ecommerce
checkpoint_dir = saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 50
train_batch_size = 1024
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']
topk = [5, 10]
valid_metric = MRR@10
valid_metric_bigger = True
eval_batch_size = 1024
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = label
TIME_FIELD = timestamp
seq_len = 50
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'timestamp', 'label']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = mask_itemseq
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.2
attn_dropout_prob = 0.2
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
mask_ratio = 0.2
loss_type = CE
ft_ratio = 0.5
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.SEQUENTIAL
neg_sampling = None
embedding_size = 64
num_layers = 2
num_heads = 2
dropout_prob = 0.2
device = cuda
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


Tue 11 Nov 2025 23:30:19 INFO  ecommerce
The number of users: 2609
Average actions of users: 7.017254601226994
The number of items: 96
Average actions of items: 192.6421052631579
The number of inters: 18301
The sparsity of the dataset: 92.69316149227035%
Remain Fields: ['user_id', 'item_id', 'timestamp', 'label']
Tue 11 Nov 2025 23:30:20 INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
Tue 11 Nov 2025 23:30:20 INFO  [Evaluation]: eval_batch_size = [1024] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
Tue 11 Nov 2025 23:30:21 INFO  BERT4Rec(
  (item_embedding): Embedding(97, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (trm_encoder): TransformerEncoder(
    (layer): ModuleList(
      (0-1): 2 x TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.2, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.2, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.2, inplace=False)
        )
      )
    )
  )
  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.2, inplace=False)
  (output_ffn): Linear(in_features=64, out_features=64, bias=True)
  (output_gelu): GELU(approximate='none')
  (output_ln): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
)
Trainable parameters: 113888
Tue 11 Nov 2025 23:30:21 INFO  FLOPs: 5194664.0
Tue 11 Nov 2025 23:30:25 INFO  epoch 0 training [time: 2.43s, train loss: 49.8294]
Tue 11 Nov 2025 23:30:25 INFO  epoch 0 evaluating [time: 0.27s, valid_score: 0.059100]
Tue 11 Nov 2025 23:30:25 INFO  valid result: 
recall@5 : 0.1044    recall@10 : 0.167    mrr@5 : 0.0511    mrr@10 : 0.0591    ndcg@5 : 0.0643    ndcg@10 : 0.0842    hit@5 : 0.1044    hit@10 : 0.167    precision@5 : 0.0209    precision@10 : 0.0167
Tue 11 Nov 2025 23:30:25 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
Tue 11 Nov 2025 23:30:32 INFO  epoch 1 training [time: 6.88s, train loss: 49.0012]
Tue 11 Nov 2025 23:30:35 INFO  epoch 1 evaluating [time: 3.33s, valid_score: 0.105500]
Tue 11 Nov 2025 23:30:35 INFO  valid result: 
recall@5 : 0.1784    recall@10 : 0.291    mrr@5 : 0.0905    mrr@10 : 0.1055    ndcg@5 : 0.1122    ndcg@10 : 0.1487    hit@5 : 0.1784    hit@10 : 0.291    precision@5 : 0.0357    precision@10 : 0.0291
Tue 11 Nov 2025 23:30:35 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
Tue 11 Nov 2025 23:30:37 INFO  epoch 2 training [time: 1.71s, train loss: 46.5965]
Tue 11 Nov 2025 23:30:37 INFO  epoch 2 evaluating [time: 0.21s, valid_score: 0.302600]
Tue 11 Nov 2025 23:30:37 INFO  valid result: 
recall@5 : 0.4744    recall@10 : 0.601    mrr@5 : 0.2855    mrr@10 : 0.3026    ndcg@5 : 0.3321    ndcg@10 : 0.3733    hit@5 : 0.4744    hit@10 : 0.601    precision@5 : 0.0949    precision@10 : 0.0601
Tue 11 Nov 2025 23:30:37 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
Tue 11 Nov 2025 23:30:39 INFO  epoch 3 training [time: 1.31s, train loss: 42.5321]
Tue 11 Nov 2025 23:30:39 INFO  epoch 3 evaluating [time: 0.24s, valid_score: 0.519400]
Tue 11 Nov 2025 23:30:39 INFO  valid result: 
recall@5 : 0.6614    recall@10 : 0.7317    mrr@5 : 0.5097    mrr@10 : 0.5194    ndcg@5 : 0.5475    ndcg@10 : 0.5706    hit@5 : 0.6614    hit@10 : 0.7317    precision@5 : 0.1323    precision@10 : 0.0732
Tue 11 Nov 2025 23:30:39 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
Tue 11 Nov 2025 23:30:40 INFO  epoch 4 training [time: 1.30s, train loss: 38.5041]
Tue 11 Nov 2025 23:30:40 INFO  epoch 4 evaluating [time: 0.22s, valid_score: 0.636800]
Tue 11 Nov 2025 23:30:40 INFO  valid result: 
recall@5 : 0.7331    recall@10 : 0.7749    mrr@5 : 0.6313    mrr@10 : 0.6368    ndcg@5 : 0.6572    ndcg@10 : 0.6706    hit@5 : 0.7331    hit@10 : 0.7749    precision@5 : 0.1466    precision@10 : 0.0775
Tue 11 Nov 2025 23:30:40 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
Tue 11 Nov 2025 23:30:42 INFO  epoch 5 training [time: 1.38s, train loss: 35.0368]
Tue 11 Nov 2025 23:30:42 INFO  epoch 5 evaluating [time: 0.12s, valid_score: 0.662500]
Tue 11 Nov 2025 23:30:42 INFO  valid result: 
recall@5 : 0.7485    recall@10 : 0.7898    mrr@5 : 0.657    mrr@10 : 0.6625    ndcg@5 : 0.6802    ndcg@10 : 0.6935    hit@5 : 0.7485    hit@10 : 0.7898    precision@5 : 0.1497    precision@10 : 0.079
Tue 11 Nov 2025 23:30:42 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
Tue 11 Nov 2025 23:30:43 INFO  epoch 6 training [time: 1.22s, train loss: 31.6453]
Tue 11 Nov 2025 23:30:43 INFO  epoch 6 evaluating [time: 0.16s, valid_score: 0.681800]
Tue 11 Nov 2025 23:30:43 INFO  valid result: 
recall@5 : 0.7508    recall@10 : 0.7966    mrr@5 : 0.6755    mrr@10 : 0.6818    ndcg@5 : 0.6944    ndcg@10 : 0.7094    hit@5 : 0.7508    hit@10 : 0.7966    precision@5 : 0.1502    precision@10 : 0.0797
Tue 11 Nov 2025 23:30:43 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
Tue 11 Nov 2025 23:30:45 INFO  epoch 7 training [time: 1.40s, train loss: 28.7838]
Tue 11 Nov 2025 23:30:45 INFO  epoch 7 evaluating [time: 0.11s, valid_score: 0.707800]
Tue 11 Nov 2025 23:30:45 INFO  valid result: 
recall@5 : 0.769    recall@10 : 0.8116    mrr@5 : 0.7022    mrr@10 : 0.7078    ndcg@5 : 0.719    ndcg@10 : 0.7327    hit@5 : 0.769    hit@10 : 0.8116    precision@5 : 0.1538    precision@10 : 0.0812
Tue 11 Nov 2025 23:30:45 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
Tue 11 Nov 2025 23:30:46 INFO  epoch 8 training [time: 1.32s, train loss: 25.9194]
Tue 11 Nov 2025 23:30:46 INFO  epoch 8 evaluating [time: 0.17s, valid_score: 0.769600]
Tue 11 Nov 2025 23:30:46 INFO  valid result: 
recall@5 : 0.8112    recall@10 : 0.8438    mrr@5 : 0.7653    mrr@10 : 0.7696    ndcg@5 : 0.7768    ndcg@10 : 0.7872    hit@5 : 0.8112    hit@10 : 0.8438    precision@5 : 0.1622    precision@10 : 0.0844
Tue 11 Nov 2025 23:30:46 INFO  Saving current: saved/BERT4Rec-Nov-11-2025_23-30-21.pth
